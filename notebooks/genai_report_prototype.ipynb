{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "id": "title",
   "metadata": {},
   "source": [
    "# GenAI Incident Report Prototype\n",
    "\n",
    "Prototypes the LLM-based incident report generation before porting to `cv_backend/routers/report.py`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-1",
   "metadata": {},
   "source": ["## 1. Setup"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "installs",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install openai pydantic python-dotenv --quiet\n",
    "import os\n",
    "from openai import OpenAI\n",
    "from pydantic import BaseModel\n",
    "from typing import Optional\n",
    "import uuid, time, json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-2",
   "metadata": {},
   "source": ["## 2. Data Schemas"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "schemas",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SensorSnapshot(BaseModel):\n",
    "    heart_rate: Optional[float] = None\n",
    "    spo2: Optional[float] = None\n",
    "    step_count: Optional[int] = None\n",
    "    skin_temperature: Optional[float] = None\n",
    "    timestamp: int\n",
    "\n",
    "class AnomalyEvent(BaseModel):\n",
    "    type: str\n",
    "    confidence: float\n",
    "    track_id: int\n",
    "    timestamp: int\n",
    "    duration_seconds: Optional[float] = None\n",
    "\n",
    "class IncidentReport(BaseModel):\n",
    "    report_id: str\n",
    "    generated_at: int\n",
    "    severity: str\n",
    "    summary: str\n",
    "    vitals_assessment: str\n",
    "    cv_assessment: str\n",
    "    recommended_action: str\n",
    "\n",
    "print('Schemas defined.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-3",
   "metadata": {},
   "source": ["## 3. Sample Data"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sample-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: fine-tune — swap in real event data once CV pipeline is running\n",
    "sample_anomaly = AnomalyEvent(\n",
    "    type='FALL',\n",
    "    confidence=0.87,\n",
    "    track_id=3,\n",
    "    timestamp=int(time.time() * 1000),\n",
    "    duration_seconds=2.5,\n",
    ")\n",
    "\n",
    "sample_sensor = SensorSnapshot(\n",
    "    heart_rate=105.0,\n",
    "    spo2=96.0,\n",
    "    step_count=800,\n",
    "    skin_temperature=37.1,\n",
    "    timestamp=int(time.time() * 1000),\n",
    ")\n",
    "\n",
    "location_context = 'gym'\n",
    "print('Sample data ready.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-4",
   "metadata": {},
   "source": ["## 4. Prompt Engineering"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prompt",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: fine-tune — expand system prompt with domain knowledge, severity criteria\n",
    "SYSTEM_PROMPT = (\n",
    "    'You are a medical triage assistant analyzing wearable sensor data and '\n",
    "    'computer-vision anomaly events. Respond with ONLY these fields, one per line, '\n",
    "    'in the format \"field: value\":\\n'\n",
    "    'severity (LOW/MODERATE/HIGH/CRITICAL)\\n'\n",
    "    'summary (2-3 sentences)\\n'\n",
    "    'vitals_assessment\\n'\n",
    "    'cv_assessment\\n'\n",
    "    'recommended_action'\n",
    ")\n",
    "\n",
    "def build_user_prompt(anomaly: AnomalyEvent, sensor: SensorSnapshot, location: str) -> str:\n",
    "    # TODO: fine-tune — add historical baseline comparison, user age/conditions\n",
    "    return (\n",
    "        f'Anomaly detected: {anomaly.type}.\\n'\n",
    "        f'Confidence: {anomaly.confidence:.0%}.\\n'\n",
    "        f'Duration: {anomaly.duration_seconds or \"unknown\"} seconds.\\n'\n",
    "        f'Biometrics at time of event:\\n'\n",
    "        f'  Heart rate: {sensor.heart_rate} bpm\\n'\n",
    "        f'  SpO2: {sensor.spo2}%\\n'\n",
    "        f'  Skin temperature: {sensor.skin_temperature}°C\\n'\n",
    "        f'  Step count: {sensor.step_count}\\n'\n",
    "        f'Location context: {location}.\\n'\n",
    "        'Generate a structured incident report.'\n",
    "    )\n",
    "\n",
    "prompt = build_user_prompt(sample_anomaly, sample_sensor, location_context)\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-5",
   "metadata": {},
   "source": ["## 5. LLM Call & Response Parsing"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "llm-call",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your API key — use Colab secrets or environment variable\n",
    "# from google.colab import userdata\n",
    "# os.environ['OPENAI_API_KEY'] = userdata.get('OPENAI_API_KEY')\n",
    "\n",
    "client = OpenAI()  # reads OPENAI_API_KEY from env\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model='gpt-4o-mini',\n",
    "    temperature=0.3,  # TODO: fine-tune — lower for more deterministic outputs\n",
    "    messages=[\n",
    "        {'role': 'system', 'content': SYSTEM_PROMPT},\n",
    "        {'role': 'user', 'content': prompt},\n",
    "    ],\n",
    ")\n",
    "\n",
    "raw_output = response.choices[0].message.content\n",
    "print('=== Raw LLM Output ===')\n",
    "print(raw_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-6",
   "metadata": {},
   "source": ["## 6. Parse into IncidentReport Schema"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "parse",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HACKATHON: simplify — use structured outputs / function-calling post-hackathon\n",
    "def parse_report(text: str) -> dict:\n",
    "    fields = {\n",
    "        'severity': 'MODERATE',\n",
    "        'summary': 'Anomaly detected. Manual review recommended.',\n",
    "        'vitals_assessment': 'Sensor data collected.',\n",
    "        'cv_assessment': f'CV detected {sample_anomaly.type} event.',\n",
    "        'recommended_action': 'Check on individual.',\n",
    "    }\n",
    "    for line in text.splitlines():\n",
    "        line = line.strip()\n",
    "        for key in fields:\n",
    "            prefix = f'{key}:'\n",
    "            if line.lower().startswith(prefix.lower()):\n",
    "                fields[key] = line[len(prefix):].strip()\n",
    "    return fields\n",
    "\n",
    "parsed = parse_report(raw_output)\n",
    "report = IncidentReport(\n",
    "    report_id=str(uuid.uuid4()),\n",
    "    generated_at=int(time.time() * 1000),\n",
    "    **parsed,\n",
    ")\n",
    "\n",
    "print('=== Structured Incident Report ===')\n",
    "print(report.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-7",
   "metadata": {},
   "source": [
    "## 7. Export Notes → FastAPI\n",
    "\n",
    "| Notebook cell | Maps to FastAPI file |\n",
    "|---|---|\n",
    "| `SYSTEM_PROMPT` + `build_user_prompt()` | `cv_backend/routers/report.py` |\n",
    "| `SensorSnapshot`, `AnomalyEvent`, `IncidentReport` | `cv_backend/schemas/` |\n",
    "| `parse_report()` | `cv_backend/routers/report.py` → `_parse_llm_response()` |\n",
    "\n",
    "**Next steps:**\n",
    "- Switch to OpenAI structured outputs (JSON schema) for reliable parsing\n",
    "- Add severity mapping based on biometric thresholds\n",
    "- Experiment with GPT-4o for higher quality triage reasoning"
   ]
  }
 ]
}
